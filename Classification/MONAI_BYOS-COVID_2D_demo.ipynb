{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker DICOM Training Overview\n",
    "\n",
    "In this example we will demonstrate how to integrate the [MONAI](http://monai.io) framework into Amazon SageMaker, and give example code of MONAI pre-processing transforms and neural network (DenseNet) that you can use to train a medical image classification model using DICOM images directly.  \n",
    "\n",
    "Please also visit [Build a medical image analysis pipeline on Amazon SageMaker using the MONAI framework](https://aws.amazon.com/blogs/industries/build-a-medical-image-analysis-pipeline-on-amazon-sagemaker-using-the-monai-framework/) for additional details on how to deploy the MONAI model, pipe input data from S3, and perform batch inferences using SageMaker batch transform.\n",
    "\n",
    "For more information about the PyTorch in SageMaker, please visit [sagemaker-pytorch-containers](https://github.com/aws/sagemaker-pytorch-containers) and [sagemaker-python-sdk](https://github.com/aws/sagemaker-python-sdk) github repositories.\n",
    "\n",
    "Sample dataset is obtained from this [source COVID-CT-MD](https://github.com/ShahinSHH/COVID-CT-MD). The total dataset contains volumetric chest CT scans (DICOM files) of 169 patients positive for COVID-19 infection, 60 patients with CAP (Community Acquired Pneumonia), and 76 normal patients. For this demo purpose, only 26 images are randomly selected. The selection and preprocessing are not included in this demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to MONAI\n",
    "\n",
    "MONAI is a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of PyTorch Ecosystem.\n",
    "\n",
    "Medical imaging has some unique requirememts. \n",
    "- Biomedical applications have specific requirements\n",
    "- Image modalities (MR, CT, US, etc.) require specific data processing\n",
    "- Data formats (DICOM, NIfTI, etc.) are specific to medical applications and require special support\n",
    "- Certain network architectures are designed for, or are highly suitable for, biomedical applications\n",
    "- Data transforms specific to biomedical applications, and to image modalities, are very useful when pre-processing data, augmenting data during training, and post-processing\n",
    "\n",
    "MONAI provides a framework of deep learning facilities and infrastructure to meet these needs in a flexible Pytorch-compatible way:\n",
    "\n",
    "- Data loading and handling library for biomedical file types\n",
    "- Large set of data transforms to process, regularize, and augment image date before, during, and after training\n",
    "- Library of general-purpose network, metric, and loss function definitions implementing common architectures\n",
    "- Set of ready-made components for training and inference to utilize computing infrastructure efficiently\n",
    "\n",
    "There is a **rich set of transforms** in six categories: Crop & Pad, Intensity, IO, Post-processing, Spatial, and Utilities. For more details, please visit all the transforms in MONAI. It support both Dictionary and Array format data. Transforms are composed with `Compose` to create a sequence of operations.\n",
    "You can also create custom transform if needed.\n",
    "\n",
    "There is a feature called **Dataset Caching**. MONAI provides multi-thread versions of CacheDataset to accelerate data transformation and training by storing the intermediate outcomes. Enabling this feature could potentially give up to 10x training speedup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install monai --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the dependencies needed by monai\n",
    "!pip install 'monai[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r ./code/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision  ## upgrade torchvision to ensure consistent performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import sagemaker \n",
    "\n",
    "sess = sagemaker.Session()\n",
    "env_path = Path('.') / 'set.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "bucket = sess.default_bucket() ## you can replace with your bucket for the dataset\n",
    "bucket_path=os.environ.get('BUCKET_PATH')\n",
    "user=os.environ.get('DICOM_USER')\n",
    "password = os.environ.get('DICOM_PASSWORD')\n",
    "datadir = 'data'\n",
    "print('Bucket: '+bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload training dataset in S3\n",
    "\n",
    "For this demo, we only use 25 images for model training, which is already downloaded and saved in data folder \n",
    "\n",
    "+ *.dcm are the dicome images\n",
    "+ manifest.json stores labels for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_list=os.listdir(datadir)\n",
    "\n",
    "\n",
    "image_file_list = [x  for x in image_file_list if x.endswith('dcm') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset and display them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.transforms import Compose, LoadImage, Resize, ScaleIntensity, ToTensor, SqueezeDim, RandRotate,RandFlip,RandZoom\n",
    "import matplotlib.pyplot as plt\n",
    "# define transform functions \n",
    "## preprocess the dataset before trainining using MONAI.  Based on img.shape, this is a channel last image\n",
    "train_transforms = Compose([\n",
    "    LoadImage(image_only=True),\n",
    "    ScaleIntensity(),\n",
    "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
    "    RandFlip(spatial_axis=0, prob=0.5),\n",
    "    #RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
    "    Resize(spatial_size=(512,-1)),\n",
    "    ToTensor()\n",
    "])\n",
    "img = train_transforms(datadir+'/'+image_file_list[0])\n",
    "img.shape ## check image size after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display sample of DICOM Images\n",
    "inf_test = []\n",
    "inf_test_label = []\n",
    "\n",
    "trans = Compose([LoadImage(image_only=True), Resize(spatial_size=(512,-1))])\n",
    "plt.subplots(2, 2, figsize=(8, 8))\n",
    "for i in range(0,4):\n",
    "    #s3.download_file(bucket, image_file_list[i], datadir+'/'+image_file_list[i])\n",
    "    \n",
    "    img = train_transforms(datadir+'/'+image_file_list[i])\n",
    "    print(img.shape)\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.xlabel(image_file_list[i])\n",
    "    plt.imshow(img[:,:,0], cmap='gray')\n",
    "    plt.title(image_file_list[i].split('-')[0])\n",
    "    inf_test.append(datadir+'/'+image_file_list[i])\n",
    "    inf_test_label.append(image_file_list[i].split('-')[0])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_test='test_data'\n",
    "\n",
    "image_file_list_test=os.listdir(datadir_test)\n",
    "image_file_list_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Create Sagemaker session and S3 location for DICOM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "key='CovidTraining'\n",
    "path=os.path.join(\"s3://\",bucket,key)\n",
    "\n",
    "## IF UPLOAD THE DATA TO S3, DO THE FOLLOWING STEP. we may skip the step if the the data has already been uploaded\n",
    "inputs = S3Uploader.upload(local_path=datadir, desired_s3_uri=path) \n",
    "\n",
    "print('input spec as an S3 path: {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload test data to S3\n",
    "testdir='test_data'\n",
    "test_key='test_data'\n",
    "test_data_path=os.path.join(\"s3://\",bucket,test_key)\n",
    "test= S3Uploader.upload(local_path=testdir, desired_s3_uri=test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "### Training\n",
    "\n",
    "The ```train.py``` script provides all the code we need for training and hosting a SageMaker model (model_fn function to load a model). The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* SM_MODEL_DIR: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* SM_NUM_GPUS: The number of gpus available in the current container.\n",
    "* SM_CURRENT_HOST: The name of the current container on the container network.\n",
    "* SM_HOSTS: JSON encoded list containing all the hosts .\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's fit() method, the following will be set, following the format SM_CHANNEL_[channel_name]:\n",
    "\n",
    "* SM_CHANNEL_TRAINING: A string representing the path to the directory containing data in the 'training' channel.\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers).\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to model_dir so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an argparse.ArgumentParser instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training in SageMaker\n",
    "\n",
    "The `PyTorch` class allows us to run our training function as a training job on SageMaker infrastructure.  We need to configure it with our training script, an IAM role, the number of training instances, the training instance type, and hyperparameters.  In this case we are going to run our training job on ```ml.m5.2xlarge``` instance.  But this example can be ran on one or multiple, cpu or gpu instances ([full list of available instances](https://aws.amazon.com/sagemaker/pricing/instance-types/)).  The hyperparameters parameter is a dict of values that will be passed to your training script -- you can see how to access these values in the ```monai_dicom.py``` script above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='code',\n",
    "                    role=role,\n",
    "                    framework_version='1.5.0',\n",
    "                    py_version='py3',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.4xlarge',\n",
    "                    hyperparameters={\n",
    "                        'backend': 'gloo',\n",
    "                        'epochs': 100,\n",
    "                         'seed':123\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've constructed our PyTorch object, we can fit it using the DICOM dataset we uploaded to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit({'train': inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the endpoint with the following options\n",
    "\n",
    "+ default inference with `numpy` as input\n",
    "\n",
    "+ customized inference with `JSON` file pointing to the image file in S3 [./source/inference.py]\n",
    "\n",
    "for further information, you may refer to [pytoch-inference-hander](https://github.com/aws/sagemaker-pytorch-inference-toolkit/blob/master/src/sagemaker_pytorch_serving_container/default_pytorch_inference_handler.py) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: synchronous inference directly with estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor = estimator.deploy(initial_instance_count=1,entry_point='inference.py', instance_type='ml.m5.xlarge',serializer=sagemaker.serializers.JSONSerializer(),deserializer=sagemaker.deserializers.JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": bucket,\n",
    "    \"key\":\"test_data/normal-IM0062.dcm\"}\n",
    "\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload2={\"bucket\": bucket,\n",
    "    \"key\":\"test_data/covid-IM0073.dcm\"}\n",
    "\n",
    "predictor.predict(payload2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Deploy through model data in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data=estimator.__dict__['output_path']+estimator.__dict__['_current_job_name']+'/output/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\", ## inference code with customerization\n",
    "    #source_dir=\"code\",        ## folder with the inference code\n",
    "    role=role,\n",
    "    model_data=model_data,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "predictor2 = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge',entry_point='inference.py',source_dir='code',\n",
    "                            serializer=sagemaker.serializers.JSONSerializer(),deserializer=sagemaker.deserializers.JSONDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload={\"bucket\": bucket,\n",
    "    \"key\":\"test_data/normal-IM0062.dcm\"}\n",
    "\n",
    "predictor2.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "payload2={\"bucket\": bucket,\n",
    "    \"key\":\"test_data/covid-IM0073.dcm\"}\n",
    "\n",
    "predictor2.predict(payload2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
